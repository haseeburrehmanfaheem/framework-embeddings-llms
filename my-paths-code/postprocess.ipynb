{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u1/hfaheem/.conda/envs/.env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import csv\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "checkpoint=\"Salesforce/codet5p-110m-embedding\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True).to(\"cuda\")\n",
    "def get_code_embedding(code_snippet):\n",
    "    \"\"\"\n",
    "    Generates embeddings for a given code snippet using a pre-trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - code_snippet (str): The code for which embeddings are to be generated.\n",
    "    - checkpoint (str): The model checkpoint to be used for embedding. Default is Salesforce/codet5p-110m-embedding.\n",
    "    - device (str): Device to run the model on, either 'cuda' for GPU or 'cpu' for CPU. Default is 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Embedding tensor for the input code.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode(code_snippet, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        embedding = model(inputs)[0]\n",
    "    \n",
    "    return embedding.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_name</th>\n",
       "      <th>class</th>\n",
       "      <th>method</th>\n",
       "      <th>depths</th>\n",
       "      <th>access control level</th>\n",
       "      <th>json_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Lcom.android.server.pm.UserManagerService</td>\n",
       "      <td>Lcom/android/server/pm/UserManagerService</td>\n",
       "      <td>getUserInfo(I)Landroid/content/pm/UserInfo;</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public U...</td>\n",
       "      <td>SYS_OR_SIG</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Lcom.android.server.pm.UserManagerService</td>\n",
       "      <td>Lcom/android/server/pm/UserManagerService</td>\n",
       "      <td>getUserBadgeResId(I)I</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public i...</td>\n",
       "      <td>SYS_OR_SIG</td>\n",
       "      <td>{'Sinks': [['UserTypeDetails v2 = p0.getUserTy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Lcom.android.server.pm.UserManagerService</td>\n",
       "      <td>Lcom/android/server/pm/UserManagerService</td>\n",
       "      <td>isUserSwitcherEnabled(I)Z</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public b...</td>\n",
       "      <td>SYS_OR_SIG</td>\n",
       "      <td>{'Sinks': [['int v4 = Settings$Global.getInt(v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Lcom.android.server.pm.UserManagerService</td>\n",
       "      <td>Lcom/android/server/pm/UserManagerService</td>\n",
       "      <td>getProfiles(IZ)Ljava/util/List;</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public L...</td>\n",
       "      <td>SYS_OR_SIG</td>\n",
       "      <td>{'Sinks': [['StringBuilder v1 = new StringBuil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Lcom.android.server.pm.UserManagerService</td>\n",
       "      <td>Lcom/android/server/pm/UserManagerService</td>\n",
       "      <td>getUserRestrictionSources(Ljava/lang/String;I)...</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public L...</td>\n",
       "      <td>SYS_OR_SIG</td>\n",
       "      <td>{'Sinks': [['boolean v4 = p0.hasBaseUserRestri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  service_name  \\\n",
       "325  Lcom.android.server.pm.UserManagerService   \n",
       "326  Lcom.android.server.pm.UserManagerService   \n",
       "327  Lcom.android.server.pm.UserManagerService   \n",
       "328  Lcom.android.server.pm.UserManagerService   \n",
       "329  Lcom.android.server.pm.UserManagerService   \n",
       "\n",
       "                                         class  \\\n",
       "325  Lcom/android/server/pm/UserManagerService   \n",
       "326  Lcom/android/server/pm/UserManagerService   \n",
       "327  Lcom/android/server/pm/UserManagerService   \n",
       "328  Lcom/android/server/pm/UserManagerService   \n",
       "329  Lcom/android/server/pm/UserManagerService   \n",
       "\n",
       "                                                method  \\\n",
       "325        getUserInfo(I)Landroid/content/pm/UserInfo;   \n",
       "326                              getUserBadgeResId(I)I   \n",
       "327                          isUserSwitcherEnabled(I)Z   \n",
       "328                    getProfiles(IZ)Ljava/util/List;   \n",
       "329  getUserRestrictionSources(Ljava/lang/String;I)...   \n",
       "\n",
       "                                                depths access control level  \\\n",
       "325  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public U...           SYS_OR_SIG   \n",
       "326  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public i...           SYS_OR_SIG   \n",
       "327  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public b...           SYS_OR_SIG   \n",
       "328  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public L...           SYS_OR_SIG   \n",
       "329  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public L...           SYS_OR_SIG   \n",
       "\n",
       "                                           json_answer  \n",
       "325                                               None  \n",
       "326  {'Sinks': [['UserTypeDetails v2 = p0.getUserTy...  \n",
       "327  {'Sinks': [['int v4 = Settings$Global.getInt(v...  \n",
       "328  {'Sinks': [['StringBuilder v1 = new StringBuil...  \n",
       "329  {'Sinks': [['boolean v4 = p0.hasBaseUserRestri...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/u1/hfaheem/DLAndroidArtifact/my-paths-code/output/week1/output1/android_services_methods.parquet\"\n",
    "df = pd.read_parquet(file_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows = 85\n",
      "row with valid json  = 82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_json_answer(json_answer, n=2):\n",
    "    global counter\n",
    "    all = []\n",
    "    try:\n",
    "        arrays = json_answer['Sinks']\n",
    "        for i, array in enumerate(arrays, 1):\n",
    "            if i > n:  # Limit the number of joins to `n`\n",
    "                break\n",
    "            joined = '\\n'.join(array)\n",
    "            all.append(joined)\n",
    "    except:    \n",
    "        return []\n",
    "    counter += 1\n",
    "    return all\n",
    "\n",
    "counter = 0\n",
    "# Step 2: Apply to create a new column for joined json_answer\n",
    "df['sink_code'] = df['json_answer'].apply(process_json_answer)\n",
    "\n",
    "# display the first row first column of the DataFrame\n",
    "print(f\"total rows = {len(df)}\")\n",
    "print(f\"row with valid json  = {counter}\")\n",
    "df.head()\n",
    "df.iloc[0][\"sink_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 85/85 [00:01<00:00, 70.09it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"embeddings\"] = None\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Rows\"):\n",
    "    code_snippets = row[\"sink_code\"]\n",
    "    embeddings = []\n",
    "    for each in code_snippets:\n",
    "        code_embedding = get_code_embedding(each)\n",
    "        embeddings.append(code_embedding)\n",
    "    df.at[index, \"embeddings\"] = embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the most similar code(prolly ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Similarities:   0%|          | 0/85 [00:00<?, ?it/s]/tmp/ipykernel_20623/526392682.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sim = torch.nn.functional.cosine_similarity(torch.tensor(emb1), torch.tensor(emb2), dim=0).item()\n",
      "Computing Similarities: 100%|██████████| 85/85 [00:01<00:00, 70.31it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "similarities = {}\n",
    "\n",
    "\n",
    "for index1, row1 in tqdm(df.iterrows(), total=len(df), desc=\"Computing Similarities\"):\n",
    "    ep1_id = row1[\"method\"]  # name of the EP1\n",
    "    ep1_embeddings = row1[\"embeddings\"] # list of embeddings for the EP1\n",
    "    ep1_sink_code = row1[\"sink_code\"] # list of code snippets for the EP1\n",
    "    \n",
    "    closest_ep = None\n",
    "    max_similarity = -1\n",
    "    similar_sink_pair = None\n",
    "    \n",
    "    for index2, row2 in df.iterrows():\n",
    "        if index1 == index2:\n",
    "            continue  \n",
    "        \n",
    "        ep2_id = row2[\"method\"] # name of the EP2\n",
    "        ep2_embeddings = row2[\"embeddings\"] # list of embeddings for the EP2\n",
    "        ep2_sink_code = row2[\"sink_code\"]  # list of code snippets for the EP2\n",
    "        \n",
    "        # Compute pairwise similarities between all embeddings of EP1 and EP2\n",
    "        for i, emb1 in enumerate(ep1_embeddings):\n",
    "            for j, emb2 in enumerate(ep2_embeddings):\n",
    "                sim = torch.nn.functional.cosine_similarity(torch.tensor(emb1), torch.tensor(emb2), dim=0).item()\n",
    "                if sim > max_similarity:\n",
    "                    max_similarity = sim\n",
    "                    closest_ep = ep2_id\n",
    "                    similar_sink_pair = (ep1_sink_code[i], ep2_sink_code[j])  \n",
    "    \n",
    "    similarities[ep1_id] = {\n",
    "        \"closest_ep\": closest_ep,\n",
    "        \"max_similarity\": max_similarity,\n",
    "        \"similar_sink_pair\": similar_sink_pair\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep, details in similarities.items():\n",
    "    if details['similar_sink_pair'] is None or details['closest_ep'] is None:\n",
    "        print(f\"EP {ep} has no similar EPs.\")\n",
    "    else:\n",
    "        print(f\"EP {ep} is most similar to EP {details['closest_ep']} with similarity {details['max_similarity']:.4f}\")\n",
    "        print(f\"Similar sink codes:\\nEP {ep}: \\n{details['similar_sink_pair'][0]}\\nEP \\n{details['closest_ep']}: \\n{details['similar_sink_pair'][1]}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get >0.8 similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Similarities:   0%|          | 0/85 [00:00<?, ?it/s]/tmp/ipykernel_20623/1097580516.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sim = torch.nn.functional.cosine_similarity(torch.tensor(emb1), torch.tensor(emb2), dim=0).item()\n",
      "Computing Similarities: 100%|██████████| 85/85 [00:01<00:00, 69.65it/s]\n"
     ]
    }
   ],
   "source": [
    "similarities = {}\n",
    "\n",
    "for index1, row1 in tqdm(df.iterrows(), total=len(df), desc=\"Computing Similarities\"):\n",
    "    ep1_id = row1[\"method\"] # name of the EP1\n",
    "    ep1_embeddings = row1[\"embeddings\"] # list of embeddings for the EP1\n",
    "    ep1_sink_code = row1[\"sink_code\"] # list of code snippets for the EP1\n",
    "    \n",
    "    similar_sink_pairs = []  # List to store all similar sink code pairs with similarity > 0.8\n",
    "    \n",
    "    for index2, row2 in df.iterrows():\n",
    "        if index1 == index2:\n",
    "            continue  \n",
    "        \n",
    "        ep2_id = row2[\"method\"] # name of the EP2\n",
    "        ep2_embeddings = row2[\"embeddings\"] # list of embeddings for the EP2\n",
    "        ep2_sink_code = row2[\"sink_code\"] # list of code snippets for the EP2  \n",
    "        \n",
    "        # Compute similarities\n",
    "        for i, emb1 in enumerate(ep1_embeddings):\n",
    "            for j, emb2 in enumerate(ep2_embeddings):\n",
    "                sim = torch.nn.functional.cosine_similarity(torch.tensor(emb1), torch.tensor(emb2), dim=0).item()\n",
    "                if sim > 0.8:  # Only consider pairs with similarity > 0.8\n",
    "                    similar_sink_pairs.append({\n",
    "                        \"similarity\": sim,\n",
    "                        \"ep1_code\": ep1_sink_code[i],\n",
    "                        \"ep2_id\": ep2_id,\n",
    "                        \"ep2_code\": ep2_sink_code[j]\n",
    "                    })\n",
    "    \n",
    "    # Store all similar pairs for the current EP\n",
    "    similarities[ep1_id] = similar_sink_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "for ep, similar_pairs in similarities.items():\n",
    "    if not similar_pairs:\n",
    "        print(f\"EP {ep} has no similar EPs with similarity > 0.8.\")\n",
    "    else:\n",
    "        print(f\"EP {ep} has the following similar sink code pairs with similarity > 0.8:\")\n",
    "        for pair in similar_pairs:\n",
    "            print(f\"  - Similarity: {pair['similarity']:.4f}\")\n",
    "            print(f\"    EP {ep}: \\n{pair['ep1_code']}\")\n",
    "            print(f\"    EP {pair['ep2_id']}: \\n{pair['ep2_code']}\")\n",
    "            print()\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write >0.8 similar and unique with top similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to ./similarities\n"
     ]
    }
   ],
   "source": [
    "CSV_FILE = './similarities'\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(CSV_FILE+ \"_allcode\" + \".csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write header\n",
    "    writer.writerow([\"EP1_ID\", \"EP2_ID\", \"EP1_Code\", \"EP2_Code\", \"Similarity\"])\n",
    "\n",
    "    # Iterate through the data and write each entry\n",
    "    for ep, similar_pairs in similarities.items():\n",
    "        if similar_pairs:\n",
    "            for pair in similar_pairs:\n",
    "                writer.writerow([\n",
    "                    ep,\n",
    "                    pair['ep2_id'],\n",
    "                    pair['ep1_code'].replace(\"\\n\", \" \"),  # Replace newlines for better CSV readability\n",
    "                    pair['ep2_code'].replace(\"\\n\", \" \"),  # Replace newlines for better CSV readability\n",
    "                    pair['similarity']\n",
    "                ])\n",
    "        else:\n",
    "            writer.writerow([ep, \"No similar EPs with similarity > 0.8\", \"\", \"\", \"\"])\n",
    "\n",
    "# Writing the data to a CSV file\n",
    "with open(CSV_FILE + \"_score\" + \".csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow([\"EP\", \"EP2_ID\", \"Max_Similarity\"])\n",
    "    \n",
    "    for ep, similar_pairs in similarities.items():\n",
    "        if not similar_pairs:\n",
    "            writer.writerow([ep, \"No similar EPs\", \"\"])\n",
    "        else:\n",
    "            max_similarity_per_ep2 = {}\n",
    "            for pair in similar_pairs:\n",
    "                ep2_id = pair['ep2_id']\n",
    "                similarity = pair['similarity']\n",
    "                if ep2_id not in max_similarity_per_ep2:\n",
    "                    max_similarity_per_ep2[ep2_id] = similarity\n",
    "                else:\n",
    "                    max_similarity_per_ep2[ep2_id] = max(max_similarity_per_ep2[ep2_id], similarity)\n",
    "            \n",
    "            # Sorting the EP2 IDs by similarity in descending order\n",
    "            sorted_ep2_ids = sorted(max_similarity_per_ep2.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Writing sorted EP2 IDs and their max similarity\n",
    "            for ep2_id, max_similarity in sorted_ep2_ids:\n",
    "                writer.writerow([ep, ep2_id, f\"{max_similarity:.4f}\"])\n",
    "\n",
    "\n",
    "\n",
    "with open(CSV_FILE + \"_top2code\" + \".csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write header\n",
    "    writer.writerow([\"EP1_ID\", \"EP2_ID\", \"EP1_Code\", \"EP2_Code\", \"Similarity\"])\n",
    "\n",
    "    # Iterate through the data and write only the top 2 most similar pairs\n",
    "    for ep, similar_pairs in similarities.items():\n",
    "        \n",
    "        if similar_pairs:\n",
    "            # Sort the pairs by similarity in descending order\n",
    "            top_pairs = sorted(similar_pairs, key=lambda x: x[\"similarity\"], reverse=True)[:2]\n",
    "            for pair in top_pairs:\n",
    "                writer.writerow([\n",
    "                    ep,\n",
    "                    pair['ep2_id'],\n",
    "                    pair['ep1_code'].replace(\"\\n\", \" \"),  # Replace newlines for better CSV readability\n",
    "                    pair['ep2_code'].replace(\"\\n\", \" \"),  # Replace newlines for better CSV readability\n",
    "                    pair['similarity']\n",
    "                ])\n",
    "        else:\n",
    "            writer.writerow([ep, \"No similar EPs with similarity > 0.8\", \"\", \"\", \"\"])\n",
    "\n",
    "print(f\"Data has been written to {CSV_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
