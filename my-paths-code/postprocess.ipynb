{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u1/hfaheem/.conda/envs/.env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import csv\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "checkpoint=\"Salesforce/codet5p-110m-embedding\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True).to(\"cuda\")\n",
    "def get_code_embedding(code_snippet):\n",
    "    \"\"\"\n",
    "    Generates embeddings for a given code snippet using a pre-trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - code_snippet (str): The code for which embeddings are to be generated.\n",
    "    - checkpoint (str): The model checkpoint to be used for embedding. Default is Salesforce/codet5p-110m-embedding.\n",
    "    - device (str): Device to run the model on, either 'cuda' for GPU or 'cpu' for CPU. Default is 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Embedding tensor for the input code.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode(code_snippet, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        embedding = model(inputs)[0]\n",
    "    \n",
    "    return embedding.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_name</th>\n",
       "      <th>class</th>\n",
       "      <th>method</th>\n",
       "      <th>depths</th>\n",
       "      <th>access control level</th>\n",
       "      <th>json_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lcom.android.server.broadcastradio.BroadcastRa...</td>\n",
       "      <td>Lcom/android/server/broadcastradio/BroadcastRa...</td>\n",
       "      <td>addAnnouncementListener([ILandroid/hardware/ra...</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public I...</td>\n",
       "      <td>SYS_OR_SIG</td>\n",
       "      <td>{\"Sinks\": [[\"ICloseHandle v14 = v13.addAnnounc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lcom.android.server.broadcastradio.BroadcastRa...</td>\n",
       "      <td>Lcom/android/server/broadcastradio/BroadcastRa...</td>\n",
       "      <td>listModules()Ljava/util/List;</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public L...</td>\n",
       "      <td>SYS_OR_SIG</td>\n",
       "      <td>{\"Sinks\": [[\"ArrayList v2 = new ArrayList();\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lcom.android.server.broadcastradio.BroadcastRa...</td>\n",
       "      <td>Lcom/android/server/broadcastradio/BroadcastRa...</td>\n",
       "      <td>openTuner(ILandroid/hardware/radio/RadioManage...</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public I...</td>\n",
       "      <td>SYS_OR_SIG</td>\n",
       "      <td>{\"Sinks\": [[\"ITuner v11 = v10.openSession(p1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lcom.android.server.soundtrigger_middleware.So...</td>\n",
       "      <td>Lcom/android/server/soundtrigger_middleware/So...</td>\n",
       "      <td>&lt;clinit&gt;()V</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public v...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>{\"Sinks\": []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lcom.android.server.soundtrigger_middleware.So...</td>\n",
       "      <td>Lcom/android/server/soundtrigger_middleware/So...</td>\n",
       "      <td>attachAsOriginator(ILandroid/media/permission/...</td>\n",
       "      <td>[{'depth': 0, 'java_code': 'depth : 0\n",
       "public I...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>{\"Sinks\": [[\"Object v1 = Objects.requireNonNul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        service_name  \\\n",
       "0  Lcom.android.server.broadcastradio.BroadcastRa...   \n",
       "1  Lcom.android.server.broadcastradio.BroadcastRa...   \n",
       "2  Lcom.android.server.broadcastradio.BroadcastRa...   \n",
       "3  Lcom.android.server.soundtrigger_middleware.So...   \n",
       "4  Lcom.android.server.soundtrigger_middleware.So...   \n",
       "\n",
       "                                               class  \\\n",
       "0  Lcom/android/server/broadcastradio/BroadcastRa...   \n",
       "1  Lcom/android/server/broadcastradio/BroadcastRa...   \n",
       "2  Lcom/android/server/broadcastradio/BroadcastRa...   \n",
       "3  Lcom/android/server/soundtrigger_middleware/So...   \n",
       "4  Lcom/android/server/soundtrigger_middleware/So...   \n",
       "\n",
       "                                              method  \\\n",
       "0  addAnnouncementListener([ILandroid/hardware/ra...   \n",
       "1                      listModules()Ljava/util/List;   \n",
       "2  openTuner(ILandroid/hardware/radio/RadioManage...   \n",
       "3                                        <clinit>()V   \n",
       "4  attachAsOriginator(ILandroid/media/permission/...   \n",
       "\n",
       "                                              depths access control level  \\\n",
       "0  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public I...           SYS_OR_SIG   \n",
       "1  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public L...           SYS_OR_SIG   \n",
       "2  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public I...           SYS_OR_SIG   \n",
       "3  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public v...                 NONE   \n",
       "4  [{'depth': 0, 'java_code': 'depth : 0\n",
       "public I...                 NONE   \n",
       "\n",
       "                                         json_answer  \n",
       "0  {\"Sinks\": [[\"ICloseHandle v14 = v13.addAnnounc...  \n",
       "1  {\"Sinks\": [[\"ArrayList v2 = new ArrayList();\",...  \n",
       "2  {\"Sinks\": [[\"ITuner v11 = v10.openSession(p1, ...  \n",
       "3                                      {\"Sinks\": []}  \n",
       "4  {\"Sinks\": [[\"Object v1 = Objects.requireNonNul...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/u1/hfaheem/DLAndroidArtifact/my-paths-code/output3/results/android_services_methods.parquet\"\n",
    "df = pd.read_parquet(file_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows = 500\n",
      "row with valid json  = 471\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "def process_json_answer(json_answer, n=2): # todo: change n to float(\"inf\")\n",
    "    global counter\n",
    "    all = []\n",
    "    if isinstance(json_answer, str):  # If it's a string, parse it\n",
    "        try:\n",
    "            json_answer = json.loads(json_answer)\n",
    "        except json.JSONDecodeError:\n",
    "            # print(\"Invalid JSON format\")\n",
    "            return []\n",
    "    try:\n",
    "        arrays = json_answer['Sinks']\n",
    "        for i, array in enumerate(arrays, 1):\n",
    "            if i > n:  # Limit the number of joins to `n`\n",
    "                break\n",
    "            joined = '\\n'.join(array)\n",
    "            all.append(joined)\n",
    "    except:    \n",
    "        return []\n",
    "    counter += 1\n",
    "    return all\n",
    "\n",
    "counter = 0\n",
    "# Step 2: Apply to create a new column for joined json_answer\n",
    "df['sink_code'] = df['json_answer'].apply(process_json_answer)\n",
    "\n",
    "# display the first row first column of the DataFrame\n",
    "print(f\"total rows = {len(df)}\")\n",
    "print(f\"row with valid json  = {counter}\")\n",
    "# df.head()\n",
    "# df.iloc[0][\"sink_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 500/500 [00:06<00:00, 75.22it/s] \n"
     ]
    }
   ],
   "source": [
    "df[\"embeddings\"] = None\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Rows\"):\n",
    "    code_snippets = row[\"sink_code\"]\n",
    "    embeddings = []\n",
    "    for each in code_snippets:\n",
    "        code_embedding = get_code_embedding(each)\n",
    "        embeddings.append(code_embedding)\n",
    "    df.at[index, \"embeddings\"] = embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the most similar code(prolly ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Similarities:   0%|          | 0/500 [00:00<?, ?it/s]/tmp/ipykernel_6003/526392682.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sim = torch.nn.functional.cosine_similarity(torch.tensor(emb1), torch.tensor(emb2), dim=0).item()\n",
      "Computing Similarities:   0%|          | 2/500 [00:00<00:46, 10.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Similarities: 100%|██████████| 500/500 [00:37<00:00, 13.49it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "similarities = {}\n",
    "\n",
    "\n",
    "for index1, row1 in tqdm(df.iterrows(), total=len(df), desc=\"Computing Similarities\"):\n",
    "    ep1_id = row1[\"method\"]  # name of the EP1\n",
    "    ep1_embeddings = row1[\"embeddings\"] # list of embeddings for the EP1\n",
    "    ep1_sink_code = row1[\"sink_code\"] # list of code snippets for the EP1\n",
    "    \n",
    "    closest_ep = None\n",
    "    max_similarity = -1\n",
    "    similar_sink_pair = None\n",
    "    \n",
    "    for index2, row2 in df.iterrows():\n",
    "        if index1 == index2:\n",
    "            continue  \n",
    "        \n",
    "        ep2_id = row2[\"method\"] # name of the EP2\n",
    "        ep2_embeddings = row2[\"embeddings\"] # list of embeddings for the EP2\n",
    "        ep2_sink_code = row2[\"sink_code\"]  # list of code snippets for the EP2\n",
    "        \n",
    "        # Compute pairwise similarities between all embeddings of EP1 and EP2\n",
    "        for i, emb1 in enumerate(ep1_embeddings):\n",
    "            for j, emb2 in enumerate(ep2_embeddings):\n",
    "                sim = torch.nn.functional.cosine_similarity(torch.tensor(emb1), torch.tensor(emb2), dim=0).item()\n",
    "                if sim > max_similarity:\n",
    "                    max_similarity = sim\n",
    "                    closest_ep = ep2_id\n",
    "                    similar_sink_pair = (ep1_sink_code[i], ep2_sink_code[j])  \n",
    "    \n",
    "    similarities[ep1_id] = {\n",
    "        \"closest_ep\": closest_ep,\n",
    "        \"max_similarity\": max_similarity,\n",
    "        \"similar_sink_pair\": similar_sink_pair\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep, details in similarities.items():\n",
    "    if details['similar_sink_pair'] is None or details['closest_ep'] is None:\n",
    "        print(f\"EP {ep} has no similar EPs.\")\n",
    "    else:\n",
    "        print(f\"EP {ep} is most similar to EP {details['closest_ep']} with similarity {details['max_similarity']:.4f}\")\n",
    "        print(f\"Similar sink codes:\\nEP {ep}: \\n{details['similar_sink_pair'][0]}\\nEP \\n{details['closest_ep']}: \\n{details['similar_sink_pair'][1]}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get >0.8 similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Similarities:   0%|          | 0/500 [00:00<?, ?it/s]/tmp/ipykernel_6003/2290205527.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sim = torch.nn.functional.cosine_similarity(torch.tensor(emb1), torch.tensor(emb2), dim=0).item()\n",
      "Computing Similarities: 100%|██████████| 500/500 [00:37<00:00, 13.47it/s]\n"
     ]
    }
   ],
   "source": [
    "similarities = {}\n",
    "\n",
    "for index1, row1 in tqdm(df.iterrows(), total=len(df), desc=\"Computing Similarities\"):\n",
    "    ep1_id = row1[\"method\"] # name of the EP1\n",
    "    ep1_embeddings = row1[\"embeddings\"] # list of embeddings for the EP1\n",
    "    ep1_sink_code = row1[\"sink_code\"] # list of code snippets for the EP1\n",
    "    \n",
    "    similar_sink_pairs = []  # List to store all similar sink code pairs with similarity > 0.8\n",
    "    \n",
    "    for index2, row2 in df.iterrows():\n",
    "        if index1 == index2:\n",
    "            continue  \n",
    "        \n",
    "        ep2_id = row2[\"method\"] # name of the EP2\n",
    "        ep2_embeddings = row2[\"embeddings\"] # list of embeddings for the EP2\n",
    "        ep2_sink_code = row2[\"sink_code\"] # list of code snippets for the EP2  \n",
    "        \n",
    "        # Compute similarities\n",
    "        for i, emb1 in enumerate(ep1_embeddings):\n",
    "            for j, emb2 in enumerate(ep2_embeddings):\n",
    "                sim = torch.nn.functional.cosine_similarity(torch.tensor(emb1), torch.tensor(emb2), dim=0).item()\n",
    "                if sim > 0.8:  # Only consider pairs with similarity > 0.5, we can filter later\n",
    "                    similar_sink_pairs.append({\n",
    "                        \"similarity\": sim,\n",
    "                        \"ep1_code\": ep1_sink_code[i],\n",
    "                        \"ep2_id\": ep2_id,\n",
    "                        \"ep2_code\": ep2_sink_code[j]\n",
    "                    })\n",
    "    \n",
    "    # Store all similar pairs for the current EP\n",
    "    similarities[ep1_id] = similar_sink_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "for ep, similar_pairs in similarities.items():\n",
    "    if not similar_pairs:\n",
    "        print(f\"EP {ep} has no similar EPs with similarity > 0.8.\")\n",
    "    else:\n",
    "        print(f\"EP {ep} has the following similar sink code pairs with similarity > 0.8:\")\n",
    "        for pair in similar_pairs:\n",
    "            print(f\"  - Similarity: {pair['similarity']:.4f}\")\n",
    "            print(f\"    EP {ep}: \\n{pair['ep1_code']}\")\n",
    "            print(f\"    EP {pair['ep2_id']}: \\n{pair['ep2_code']}\")\n",
    "            print()\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write >0.8 similar and unique with top similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to ./todelete\n"
     ]
    }
   ],
   "source": [
    "CSV_FILE = './todelete'\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(CSV_FILE+ \"_allcode\" + \".csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write header\n",
    "    writer.writerow([\"EP1_ID\", \"EP2_ID\", \"EP1_Code\", \"EP2_Code\", \"Similarity\"])\n",
    "\n",
    "    # Iterate through the data and write each entry\n",
    "    for ep, similar_pairs in similarities.items():\n",
    "        if similar_pairs:\n",
    "            for pair in similar_pairs:\n",
    "                writer.writerow([\n",
    "                    ep,\n",
    "                    pair['ep2_id'],\n",
    "                    pair['ep1_code'].replace(\"\\n\", \" \"),  # Replace newlines for better CSV readability\n",
    "                    pair['ep2_code'].replace(\"\\n\", \" \"),  # Replace newlines for better CSV readability\n",
    "                    pair['similarity']\n",
    "                ])\n",
    "        else:\n",
    "            writer.writerow([ep, \"No similar EPs with similarity > 0.8\", \"\", \"\", \"\"])\n",
    "\n",
    "# Writing the data to a CSV file\n",
    "with open(CSV_FILE + \"_score\" + \".csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow([\"EP\", \"EP2_ID\", \"Max_Similarity\"])\n",
    "    \n",
    "    for ep, similar_pairs in similarities.items():\n",
    "        if not similar_pairs:\n",
    "            writer.writerow([ep, \"No similar EPs\", \"\"])\n",
    "        else:\n",
    "            max_similarity_per_ep2 = {}\n",
    "            for pair in similar_pairs:\n",
    "                ep2_id = pair['ep2_id']\n",
    "                similarity = pair['similarity']\n",
    "                if ep2_id not in max_similarity_per_ep2:\n",
    "                    max_similarity_per_ep2[ep2_id] = similarity\n",
    "                else:\n",
    "                    max_similarity_per_ep2[ep2_id] = max(max_similarity_per_ep2[ep2_id], similarity)\n",
    "            \n",
    "            # Sorting the EP2 IDs by similarity in descending order\n",
    "            sorted_ep2_ids = sorted(max_similarity_per_ep2.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Writing sorted EP2 IDs and their max similarity\n",
    "            for ep2_id, max_similarity in sorted_ep2_ids:\n",
    "                writer.writerow([ep, ep2_id, f\"{max_similarity:.4f}\"])\n",
    "\n",
    "\n",
    "\n",
    "with open(CSV_FILE + \"_top2code\" + \".csv\", mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write header\n",
    "    writer.writerow([\"EP1_ID\", \"EP2_ID\", \"EP1_Code\", \"EP2_Code\", \"Similarity\"])\n",
    "\n",
    "    # Iterate through the data and write only the top 2 most similar pairs\n",
    "    for ep, similar_pairs in similarities.items():\n",
    "        \n",
    "        if similar_pairs:\n",
    "            # Sort the pairs by similarity in descending order\n",
    "            top_pairs = sorted(similar_pairs, key=lambda x: x[\"similarity\"], reverse=True)[:2]\n",
    "            for pair in top_pairs:\n",
    "                writer.writerow([\n",
    "                    ep,\n",
    "                    pair['ep2_id'],\n",
    "                    pair['ep1_code'].replace(\"\\n\", \" \"),  # Replace newlines for better CSV readability\n",
    "                    pair['ep2_code'].replace(\"\\n\", \" \"),  # Replace newlines for better CSV readability\n",
    "                    pair['similarity']\n",
    "                ])\n",
    "        else:\n",
    "            writer.writerow([ep, \"No similar EPs with similarity > 0.8\", \"\", \"\", \"\"])\n",
    "\n",
    "print(f\"Data has been written to {CSV_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_similar_methods(similarities, top_n=2, threshold=0.8):\n",
    "    filtered = [entry for entry in similarities if entry['similarity'] > threshold]\n",
    "    sorted_results = sorted(filtered, key=lambda x: x['similarity'], reverse=True)\n",
    "    top_results = sorted_results[:top_n]\n",
    "    extracted_results = [\n",
    "        {\n",
    "            'ep2_code': entry['ep2_code'],\n",
    "            'ep2_id': entry['ep2_id'],\n",
    "            'ep1_code': entry['ep1_code'],\n",
    "            'similarity': entry['similarity']\n",
    "        }\n",
    "        for entry in top_results\n",
    "    ]\n",
    "    \n",
    "    return extracted_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "json_answer\n",
       "None                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    29\n",
       "{\"Sinks\": []}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            6\n",
       "{\"Sinks\": [[\"p0.enforceAccessPermission();\", \"p0.setWorkSourceUidToCallingUid();\"]]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     5\n",
       "{\"Sinks\": [[]]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          3\n",
       "{\"Sinks\": [[\"int v2 = Binder.getCallingUid();\", \"this.mNotificationDelegate.clearInlineReplyUriPermissions(p1, v2);\"]]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ..\n",
       "{\"Sinks\": [[\"HdmiControlService$HdmiControlStatusChangeListenerRecord v0 = new HdmiControlService$HdmiControlStatusChangeListenerRecord(p0, p1);\", \"IBinder v2 = p1.asBinder();\", \"v2.linkToDeath(v0, 0);\", \"boolean v4 = this.mHdmiControlStatusChangeListenerRecords.add(v0);\", \"HdmiControlService$9 v4 = new HdmiControlService$9(p0, v0, p1);\", \"p0.runOnServiceThread(v4);\"]]}                                                                                                                                                                                                                                                     1\n",
       "{\"Sinks\": [[\"HdmiControlService.-$$Nest$minitBinderCall(this.this$0);\", \"long v2 = Binder.clearCallingIdentity();\", \"HdmiCecConfig v3 = this.this$0.getHdmiCecConfig();\", \"v3.setIntValue(p1, p2);\"], [\"p0.enforceAccessPermission();\", \"p0.setWorkSourceUidToCallingUid();\"], [\"HdmiCecConfig$Setting v1 = p0.getSetting(p1);\", \"boolean v2 = v1.getUserConfigurable();\", \"String v3 = v1.getValueType();\", \"boolean v4 = v3.equals(\\\"int\\\");\", \"List v5 = p0.getAllowedIntValues(p1);\", \"Integer v6 = Integer.valueOf(p2);\", \"boolean v7 = v5.contains(v6);\"], [\"String v16 = Integer.toString(p2);\", \"p0.storeValue(v1, v16);\"]]}     1\n",
       "{\"Sinks\": [[\"boolean v3 = v2.hasSystemAudioDevice();\", \"HdmiDeviceInfo v1 = p0.getSafeAvrDeviceInfo();\", \"return phiInstruction;\"]]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
       "{\"Sinks\": [[\"boolean v4 = v3.setMessageHistorySize(p1);\", \"return v4;\"]]}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "{\"Sinks\": [[\"HdmiCecConfig$Setting v1 = p0.getSetting(p1);\", \"String v2 = v1.getValueType();\", \"HdmiCecConfig$Value v10 = v1.getDefaultValue();\", \"Integer v11 = v10.getIntValue();\", \"int v12 = v11.intValue();\", \"String v13 = Integer.toString(v12);\", \"String v14 = p0.retrieveValue(v1, v13);\", \"int v15 = Integer.parseInt(v14);\", \"return v15;\"], [\"HdmiCecConfig v3 = this.this$0.getHdmiCecConfig();\", \"int v4 = v3.getIntValue(p1);\", \"return v4;\"]]}                                                                                                                                                                          1\n",
       "Name: count, Length: 461, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"json_answer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 500/500 [00:00<00:00, 9093.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with valid JSON: 462\n",
      "Total rows with no top similar found: 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "no_top_similar_found = 0\n",
    "df[\"json_answer2\"] = None\n",
    "df[\"access control level predicted\"] = None\n",
    "\n",
    "\n",
    "valid_methods = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing rows\"):\n",
    "    if row[\"json_answer\"] == \"None\" or row[\"json_answer\"] == \"{\\\"Sinks\\\": []}\" or row[\"json_answer\"] == \"{\\\"Sinks\\\": [[]]}\":\n",
    "        continue\n",
    "    counter += 1\n",
    "    full_method_name = row['method']\n",
    "    method_name = row['method'].split(\"(\")[0]\n",
    "    service_name = row['service_name']\n",
    "    top_similar = get_top_similar_methods(similarities[full_method_name])\n",
    "    \n",
    "    if top_similar == []:\n",
    "        no_top_similar_found += 1\n",
    "        continue\n",
    "        # print(service_name, method_name)\n",
    "    valid_methods.append(full_method_name)\n",
    "print(f\"Total rows with valid JSON: {counter}\")\n",
    "print(f\"Total rows with no top similar found: {no_top_similar_found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_methods)\n",
    "\n",
    "\n",
    "# write in a textfile \n",
    "\n",
    "with open(\"valid_methods_to_delete.txt\", \"w\") as f:\n",
    "    for method in valid_methods:\n",
    "        f.write(method + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the text file in an array\n",
    "\n",
    "with open(\"valid_methods_to_delete.txt\", \"r\") as f:\n",
    "    valid_methods = f.readlines()\n",
    "    \n",
    "valid_methods = [method.strip() for method in valid_methods]\n",
    "len(valid_methods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
